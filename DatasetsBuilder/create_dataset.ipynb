{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import time\n",
    "import cv2\n",
    "DATASET_PATH = '../dataset'\n",
    "if DATASET_PATH not in sys.path:\n",
    "    sys.path.append(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('../dataset/scan/pose/0.txt')\n",
    "b = np.loadtxt('../dataset/scan/pose/15.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getC1TC2s(C1TW,C2TW):\n",
    "    C1TW_R = C1TW[:3,:3]\n",
    "    C2TW_R = C2TW[:3,:3]\n",
    "    C1TW_t = np.expand_dims(C1TW[:3,3], axis=1)\n",
    "    C2TW_t = np.expand_dims(C2TW[:3,3], axis=1)\n",
    "    ones=np.array([0.,0.,0.,1.])\n",
    "    R=(np.linalg.inv(C2TW_R)).dot(C1TW_R)\n",
    "    t=(np.linalg.inv(C2TW_R)).dot(C1TW_t-C2TW_t)\n",
    "    T=np.hstack((R,t))\n",
    "    T=np.vstack((T,ones))\n",
    "    T=np.linalg.inv(T)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=getC1TC2s(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.,  0., -0.,  0.],\n",
       "       [ 0., -0., -0.,  0.],\n",
       "       [-0., -0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dot(T)-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建ｄａｔａｓｅｔ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from .dataset_tools import *\n",
    "\n",
    "class SfMDataset(object):\n",
    "    def __init__(self, out_size=(320, 320), warp_aug_mode='none', flip_pair=False, max_degree=180, max_scale=np.sqrt(2), min_scale=None, compress=False, num_threads=8):\n",
    "        self.num_threads = num_threads\n",
    "        self.out_size = out_size # [height, width]\n",
    "        self.warp_aug_mode = warp_aug_mode\n",
    "        # self.warp_aug_mode = 'none'\n",
    "        # print('Disable warp_aug_mode @ SfMDataset')\n",
    "        self.compression_type = 'GZIP' if compress else None\n",
    "\n",
    "        self.depth_factor = 0.001\n",
    "        self.far_depth_val = 1000\n",
    "        self.depth_thresh = 10.0\n",
    "        self.flip_pair = flip_pair\n",
    "        self.max_scale = max_scale\n",
    "        self.min_scale = min_scale\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "    def get_dataset(self, root_dir, imroot_dir, render_paths, phase, batch_size=32, shuffle=True, num_epoch=None, seed=None, max_examples=-1):\n",
    "        \n",
    "        table_dir = os.path.join(root_dir, '../../../scannet/params/')\n",
    "        self.random_transformer = RandomTransformer(table_dir, self.warp_aug_mode, max_scale=self.max_scale, min_scale=self.min_scale, max_degree=self.max_degree)\n",
    "\n",
    "        if isinstance(render_paths, str):\n",
    "            render_paths = [render_paths]\n",
    "        num_seq = len(render_paths)\n",
    "        \n",
    "        if not root_dir.endswith('/'):\n",
    "            root_dir += '/'\n",
    "        self.root_dir = tf.convert_to_tensor(root_dir)\n",
    "\n",
    "        if not imroot_dir.endswith('/'):\n",
    "            imroot_dir += '/'\n",
    "        self.imroot_dir = tf.convert_to_tensor(imroot_dir)\n",
    "        \n",
    "        pose_tfrecords = []\n",
    "        total_num_photos = 0\n",
    "        for render in render_paths:\n",
    "            if phase == 'train':\n",
    "                if max_examples > 0:\n",
    "                    pose_fname = 'train_{}.tfrecord'.format(max_examples)\n",
    "                    size_fname = None\n",
    "                    print('Found {} (limited sample={})'.format(pose_fname, max_examples))\n",
    "                else:\n",
    "                    pose_fname = 'train.tfrecord'\n",
    "                    size_fname = 'train_size.txt'\n",
    "            elif phase == 'valid':\n",
    "                pose_fname = 'valid.tfrecord'\n",
    "                size_fname = 'valid_size.txt'\n",
    "            else:\n",
    "                if max_examples > 0 and os.path.exists(os.path.join(root_dir, render, 'pose_{}.tfrecord'.format(max_examples))):\n",
    "                    pose_fname = 'pose_{}.tfrecord'.format(max_examples)\n",
    "                    size_fname = None\n",
    "                    print('Found {} (limited sample={})'.format(pose_fname, max_examples))\n",
    "                else:\n",
    "                    pose_fname = 'pose.tfrecord'\n",
    "                    size_fname = 'size.txt'\n",
    "\n",
    "            pose_tfrecords.append(os.path.join(root_dir, render, pose_fname))\n",
    "            if size_fname is None:\n",
    "                size = max_examples\n",
    "            else:\n",
    "                with open(os.path.join(root_dir, render, size_fname)) as f:\n",
    "                    size = int(f.readline())\n",
    "                print('{} has {} examples'.format(render, size))\n",
    "                if max_examples > 0:\n",
    "                    size = min(size, max_examples)\n",
    "                    print('---> actual size={}'.format(size))\n",
    "\n",
    "            total_num_photos += size\n",
    "\n",
    "        self.total_num_photos = total_num_photos\n",
    "        self.num_photos_per_seq_data = np.array([total_num_photos], dtype=np.int32)\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(pose_tfrecords, compression_type=self.compression_type)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=self.total_num_photos, seed=seed)\n",
    "        dataset = dataset.repeat(count=num_epoch)\n",
    "        dataset = dataset.map(self.parser, num_parallel_calls=self.num_threads)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        # dataset = dataset.prefetch(buffer_size=2)\n",
    "        return dataset\n",
    "\n",
    "    def parser(self, serialized):\n",
    "        with tf.name_scope('parse_example'):\n",
    "            example = tf.parse_single_example(serialized, features={\n",
    "                'rgb1_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'rgb2_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'depth1_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'depth2_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'shape1': tf.FixedLenFeature([2], tf.int64),\n",
    "                'shape2': tf.FixedLenFeature([2], tf.int64),\n",
    "                'bbox1': tf.FixedLenFeature([4], tf.int64), # x1,x2,y1,y2\n",
    "                'bbox2': tf.FixedLenFeature([4], tf.int64),\n",
    "                'c1Tw': tf.FixedLenFeature([16], tf.float32),\n",
    "                'c2Tw': tf.FixedLenFeature([16], tf.float32),\n",
    "                'K1': tf.FixedLenFeature([9], tf.float32),\n",
    "                'K2': tf.FixedLenFeature([9], tf.float32),\n",
    "            })\n",
    "\n",
    "        # Flip images\n",
    "        if self.flip_pair:\n",
    "            # pair is always idx1 < idx2 so that it will be effective to switch pairs randomly\n",
    "            flip_example = {\n",
    "                'rgb1_filename': example['rgb2_filename'],\n",
    "                'rgb2_filename': example['rgb1_filename'],\n",
    "                'depth1_filename': example['depth2_filename'],\n",
    "                'depth2_filename': example['depth1_filename'],\n",
    "                'shape1': example['shape2'],\n",
    "                'shape2': example['shape1'],\n",
    "                'bbox1': example['bbox2'], \n",
    "                'bbox2': example['bbox1'],\n",
    "                'c1Tw': example['c2Tw'],\n",
    "                'c2Tw': example['c1Tw'],\n",
    "                'K1': example['K2'],\n",
    "                'K2': example['K1'],\n",
    "            }\n",
    "            is_flip = tf.less_equal(tf.random_uniform([]), 0.5)\n",
    "            example = tf.cond(is_flip, lambda: flip_example, lambda: example)            \n",
    "\n",
    "        shape1 = example['shape1']\n",
    "        shape2 = example['shape2']\n",
    "        c1Tw = tf.reshape(example['c1Tw'], [4,4])\n",
    "        c2Tw = tf.reshape(example['c2Tw'], [4,4])\n",
    "        K1 = tf.reshape(example['K1'], [3,3])\n",
    "        K2 = tf.reshape(example['K2'], [3,3])\n",
    "\n",
    "        bb1 = example['bbox1']\n",
    "        bb2 = example['bbox2']\n",
    "\n",
    "        rgb1_filename = self.imroot_dir + example['rgb1_filename']\n",
    "        rgb2_filename = self.imroot_dir + example['rgb2_filename']\n",
    "        depth1_filename = self.root_dir + example['depth1_filename']\n",
    "        depth2_filename = self.root_dir + example['depth2_filename']\n",
    "        \n",
    "        # return rgb1_filename, rgb2_filename, depth1_filename, depth2_filename\n",
    "\n",
    "        rgb1 = self._decode_rgb(rgb1_filename, shape1)\n",
    "        rgb2 = self._decode_rgb(rgb2_filename, shape2)\n",
    "        depth1, valid_mask1 = self._decode_depth(depth1_filename, shape1)\n",
    "        depth2, valid_mask2 = self._decode_depth(depth2_filename, shape2)\n",
    "\n",
    "        dv1 = tf.concat([depth1, valid_mask1], axis=-1)\n",
    "        dv2 = tf.concat([depth2, valid_mask2], axis=-1)\n",
    "\n",
    "        # rgbd1 = tf.concat([rgb1, depth1, valid_mask1], axis=-1)\n",
    "        # rgbd2 = tf.concat([rgb2, depth2, valid_mask2], axis=-1)\n",
    "\n",
    "        width1 = bb1[1] - bb1[0]\n",
    "        height1 = bb1[3] - bb1[2]\n",
    "        width2 = bb2[1] - bb2[0]\n",
    "        height2 = bb2[3] - bb2[2]\n",
    "        \n",
    "        # crop\n",
    "        rgb1 = tf.slice(rgb1, [bb1[2],bb1[0],0], [height1, width1, -1])\n",
    "        dv1 = tf.slice(dv1, [bb1[2],bb1[0],0], [height1, width1, -1])\n",
    "        rgb2 = tf.slice(rgb2, [bb2[2],bb2[0],0], [height2, width2, -1])\n",
    "        dv2 = tf.slice(dv2, [bb2[2],bb2[0],0], [height2, width2, -1])\n",
    "        # rgbd1 = tf.slice(rgbd1, [bb1[2],bb1[0],0], [height1, width1, -1])\n",
    "        # rgbd2 = tf.slice(rgbd2, [bb2[2],bb2[0],0], [height2, width2, -1])\n",
    "\n",
    "        # modify intrinsic matrix\n",
    "        K1 = fix_intrinsic_center(K1, tf.to_float(width1)/2, tf.to_float(height1)/2)\n",
    "        K2 = fix_intrinsic_center(K2, tf.to_float(width2)/2, tf.to_float(height2)/2)\n",
    "        \n",
    "        if self.out_size is not None:\n",
    "            sy1 = float(self.out_size[0]) / tf.to_float(tf.shape(rgb1)[0])\n",
    "            sx1 = float(self.out_size[1]) / tf.to_float(tf.shape(rgb1)[1])\n",
    "            sy2 = float(self.out_size[0]) / tf.to_float(tf.shape(rgb2)[0])\n",
    "            sx2 = float(self.out_size[1]) / tf.to_float(tf.shape(rgb2)[1])\n",
    "            S1 = make_scale_theta(sx1, sy1)\n",
    "            S2 = make_scale_theta(sx2, sy2)\n",
    "            K1 = tf.matmul(S1, K1)\n",
    "            K2 = tf.matmul(S2, K2)\n",
    "            \n",
    "            # do not use linear interpolation on depth and valid_masks\n",
    "            rgb1 = tf.image.resize_images(rgb1, (self.out_size[0],self.out_size[1]))\n",
    "            dv1 = tf.image.resize_images(dv1, (self.out_size[0],self.out_size[1]),\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            rgb2 = tf.image.resize_images(rgb2, (self.out_size[0],self.out_size[1]))\n",
    "            dv2 = tf.image.resize_images(dv2, (self.out_size[0],self.out_size[1]),\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            # rgbd1 = tf.image.resize_images(rgbd1, (self.out_size[0],self.out_size[1]))\n",
    "            # rgbd2 = tf.image.resize_images(rgbd2, (self.out_size[0],self.out_size[1]))\n",
    "\n",
    "        depth1 = tf.slice(dv1, [0,0,0], [-1,-1,1])        \n",
    "        valid_mask1 = tf.slice(dv1, [0,0,1], [-1,-1,1])        \n",
    "        depth2 = tf.slice(dv2, [0,0,0], [-1,-1,1])        \n",
    "        valid_mask2 = tf.slice(dv2, [0,0,1], [-1,-1,1])        \n",
    "\n",
    "        # Pose\n",
    "        c2Tc1, c1Tc2 = get_delta_pose(c1Tw, c2Tw)\n",
    "        \n",
    "        # get random thetas (doesnot support table-random)\n",
    "        theta_params, use_augs = self.random_transformer.get_theta_params(None)\n",
    "\n",
    "        # add in-plane rotation\n",
    "        intheta_c2Rc1 = tf.py_func(get_inplane_rotation, [c2Tc1[:3,:3]], [tf.float32])\n",
    "        intheta_c1Rc2 = tf.py_func(get_inplane_rotation, [c1Tc2[:3,:3]], [tf.float32])\n",
    "        theta_params = tf.concat([theta_params, intheta_c2Rc1, intheta_c1Rc2], axis=0)\n",
    "\n",
    "        return rgb1, rgb2, depth1, depth2, valid_mask1, valid_mask2, c2Tc1, c1Tc2, c1Tw, c2Tw, K1, K2, theta_params, use_augs\n",
    "        \n",
    "    def _decode_rgb(self, filename, shape):\n",
    "        rgb = tf.read_file(filename)\n",
    "        rgb = tf.image.decode_jpeg(rgb, 1)\n",
    "        rgb = tf.cast(rgb, tf.float32) / 255.0\n",
    "        return rgb\n",
    "    \n",
    "    def _decode_depth(self, filename, shape):\n",
    "        depth = tf.read_file(filename)\n",
    "        depth = tf.image.decode_png(depth, 1, dtype=tf.uint16) # force to load as grayscale\n",
    "        depth = tf.scalar_mul(self.depth_factor, tf.cast(depth, tf.float32))\n",
    "        is_zero = tf.equal(depth, tf.constant(0, dtype=tf.float32))\n",
    "        valid_mask = tf.cast(tf.logical_not(is_zero), tf.float32)\n",
    "        far_depth = tf.scalar_mul(self.far_depth_val, tf.ones_like(depth, dtype=tf.float32))\n",
    "        depth = tf.where(is_zero, far_depth, depth)\n",
    "        return depth, valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
