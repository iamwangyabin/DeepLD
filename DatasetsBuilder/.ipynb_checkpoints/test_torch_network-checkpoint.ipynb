{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "# import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5578"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imageio import imread, imsave\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "in_dir='../dataset/color/'\n",
    "img_paths = [x.path for x in os.scandir(in_dir) if x.name.endswith('.jpg') or x.name.endswith('.png')]\n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = imread(img_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL \n",
    "\n",
    "# plt.figure(\"dog\")\n",
    "# plt.imshow(photo)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成一个图片载入程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "loader = torchvision.transforms.Compose([\n",
    "#     transforms.Scale(imsize), \n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = PIL.Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image #assumes that you're using GPU\n",
    "\n",
    "image = image_loader(img_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 968, 1296])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, use_bias=True,downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn0=nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=5, stride=stride,padding=2, bias=use_bias)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=5, stride=stride,padding=2, bias=use_bias)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn0(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorModel(torch.nn.Module):\n",
    "    def __init__(self, num_block=3, num_channels=16,conv_ksize=5,\n",
    "                 use_bias=True, min_scale=2**-3, max_scale=1, num_scales=9):\n",
    "\n",
    "        self.inplanes = num_channels\n",
    "        self.num_blocks=num_block\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale=max_scale\n",
    "        self.num_scales=num_scales\n",
    "\n",
    "        super(DetectorModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=conv_ksize, stride=1, padding=2,\n",
    "                               bias=use_bias)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.layer=BasicBlock(self.inplanes, self.inplanes, stride=1, use_bias=True)\n",
    "        self.soft_conv=nn.Conv2d(16, 1, kernel_size=conv_ksize, stride=1, padding=2,\n",
    "                               bias=use_bias)\n",
    "        self.ori_layer=nn.Conv2d(self.inplanes,2,kernel_size=conv_ksize, stride=1, padding=2,\n",
    "                                bias=True )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        num_conv = 0\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        num_conv+=1\n",
    "        for i in range(self.num_blocks):\n",
    "            x=self.layer(x)\n",
    "            print(1)\n",
    "        x=self.bn1(x)\n",
    "        if self.num_scales == 1:\n",
    "            scale_factors = [1.0]\n",
    "        else:\n",
    "            scale_log_factors = np.linspace(np.log(self.max_scale), np.log(self.min_scale), self.num_scales)\n",
    "            scale_factors = np.exp(scale_log_factors)\n",
    "        score_maps_list = []\n",
    "\n",
    "        base_height_f = x.shape[2]\n",
    "        base_width_f = x.shape[3]\n",
    "\n",
    "        for i, s in enumerate(scale_factors):\n",
    "            feat_height = (base_height_f * s + 0.5).astype(np.uint32)\n",
    "            feat_width = (base_width_f * s + 0.5).astype(np.uint32)\n",
    "            rs_feat_maps=torch.nn.functional.interpolate(x,[feat_height, feat_width])\n",
    "            score_maps = self.soft_conv(rs_feat_maps)\n",
    "            score_maps_list.append(score_maps)\n",
    "\n",
    "#         ori_b_init=torch.nn.init.constant(np.array([1,0], dtype=np.float32))\n",
    "#         self.ori_layer.bias.data.fill_(ori_b_init)\n",
    "        ori_maps=self.ori_layer(x)\n",
    "        norm = ori_maps.norm(p=2, dim=1, keepdim=True)\n",
    "        ori_maps = ori_maps.div(norm.expand_as(ori_maps))\n",
    "    \n",
    "        endpoints={}\n",
    "        endpoints['ori_maps'] = ori_maps\n",
    "        endpoints['scale_factors'] = scale_factors\n",
    "        return score_maps_list,endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DetectorModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "score_maps_list,endpoints = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 968, 1296])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_maps_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 968, 1296])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints['ori_maps'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(score_maps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1830, -0.7260, -0.7894,  ...,  0.9956,  0.9804,  0.9982],\n",
       "          [-0.7578, -0.9286, -0.9655,  ...,  0.2057,  0.6935,  0.5808],\n",
       "          [-1.0000, -0.9009, -0.9793,  ...,  0.2473,  0.0525,  0.9998],\n",
       "          ...,\n",
       "          [-0.2711, -0.9286, -0.9931,  ...,  0.4832, -0.7531,  0.9981],\n",
       "          [ 0.0145, -0.5627, -0.9723,  ...,  0.9683,  0.0689,  0.2631],\n",
       "          [ 0.2282, -0.2648, -0.9616,  ..., -0.0847,  0.3065,  0.6306]],\n",
       "\n",
       "         [[ 0.9831, -0.6877, -0.6139,  ..., -0.0937, -0.1970,  0.0595],\n",
       "          [-0.6525, -0.3710, -0.2602,  ...,  0.9786,  0.7205,  0.8140],\n",
       "          [-0.0079, -0.4340, -0.2026,  ...,  0.9689,  0.9986,  0.0220],\n",
       "          ...,\n",
       "          [-0.9626, -0.3711, -0.1175,  ...,  0.8755,  0.6579, -0.0617],\n",
       "          [-0.9999, -0.8266, -0.2336,  ..., -0.2499, -0.9976, -0.9648],\n",
       "          [-0.9736, -0.9643, -0.2745,  ..., -0.9964, -0.9519, -0.7761]]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints['ori_maps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9.5132e-02, -2.0404e-01,  1.6202e-01,  ...,  7.7709e-04,\n",
       "            1.4454e-02, -6.6126e-03],\n",
       "          [-3.2322e-01,  1.6059e-01,  1.4056e+00,  ...,  2.4473e-01,\n",
       "            2.1986e-01,  3.3805e-01],\n",
       "          [-9.7903e-01, -4.6141e-01,  3.2169e-01,  ..., -2.4291e-01,\n",
       "           -7.3376e-01,  1.4821e-01],\n",
       "          ...,\n",
       "          [-7.8730e-01,  4.6630e-01,  2.9443e-01,  ..., -2.1323e-01,\n",
       "           -9.8827e-01, -1.2142e-01],\n",
       "          [-3.2610e-01,  2.3963e-01,  3.6654e-01,  ...,  6.8808e-01,\n",
       "            4.2732e-02,  5.7086e-01],\n",
       "          [ 3.2584e-01, -1.6511e-01,  4.7603e-01,  ..., -3.4453e-01,\n",
       "            2.9609e-02, -4.1296e-01]],\n",
       "\n",
       "         [[-1.0500e-01,  1.6093e-01,  6.0468e-01,  ...,  8.2428e-01,\n",
       "            2.4642e-01,  1.1696e-01],\n",
       "          [-1.4341e-01,  3.7865e-01,  5.7144e-01,  ...,  5.0299e-01,\n",
       "           -7.0438e-02,  1.3670e-02],\n",
       "          [ 9.8710e-02,  6.4920e-02,  1.9095e-01,  ...,  8.2882e-01,\n",
       "           -1.3654e-01, -4.4763e-01],\n",
       "          ...,\n",
       "          [-3.3516e-01,  1.1306e-01,  5.2099e-01,  ...,  1.0950e-01,\n",
       "            2.9953e-01,  3.2775e-01],\n",
       "          [-1.9001e-01,  2.9702e-01,  4.0815e-01,  ..., -6.4741e-01,\n",
       "           -2.9608e-01, -1.6865e-01],\n",
       "          [-2.6877e-01,  2.0373e-02,  1.4186e-01,  ..., -4.9949e-01,\n",
       "           -2.5301e-02,  4.5956e-01]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints['ori_maps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = endpoints['ori_maps'].norm(p=2, dim=1, keepdim=True)\n",
    "d = endpoints['ori_maps'].div(norm.expand_as(endpoints['ori_maps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.7142e-01, -7.8518e-01,  2.5882e-01,  ...,  9.4275e-04,\n",
       "            5.8555e-02, -5.6449e-02],\n",
       "          [-9.1407e-01,  3.9044e-01,  9.2637e-01,  ...,  4.3752e-01,\n",
       "            9.5232e-01,  9.9918e-01],\n",
       "          [-9.9496e-01, -9.9025e-01,  8.5992e-01,  ..., -2.8125e-01,\n",
       "           -9.8312e-01,  3.1432e-01],\n",
       "          ...,\n",
       "          [-9.2010e-01,  9.7184e-01,  4.9200e-01,  ..., -8.8956e-01,\n",
       "           -9.5701e-01, -3.4740e-01],\n",
       "          [-8.6403e-01,  6.2791e-01,  6.6816e-01,  ...,  7.2830e-01,\n",
       "            1.4284e-01,  9.5902e-01],\n",
       "          [ 7.7143e-01, -9.9247e-01,  9.5835e-01,  ..., -5.6780e-01,\n",
       "            7.6025e-01, -6.6839e-01]],\n",
       "\n",
       "         [[-7.4107e-01,  6.1927e-01,  9.6592e-01,  ...,  1.0000e+00,\n",
       "            9.9828e-01,  9.9841e-01],\n",
       "          [-4.0556e-01,  9.2063e-01,  3.7660e-01,  ...,  8.9921e-01,\n",
       "           -3.0510e-01,  4.0406e-02],\n",
       "          [ 1.0032e-01,  1.3933e-01,  5.1042e-01,  ...,  9.5964e-01,\n",
       "           -1.8294e-01, -9.4932e-01],\n",
       "          ...,\n",
       "          [-3.9169e-01,  2.3563e-01,  8.7059e-01,  ...,  4.5682e-01,\n",
       "            2.9006e-01,  9.3772e-01],\n",
       "          [-5.0344e-01,  7.7829e-01,  7.4401e-01,  ..., -6.8525e-01,\n",
       "           -9.8975e-01, -2.8332e-01],\n",
       "          [-6.3631e-01,  1.2247e-01,  2.8559e-01,  ..., -8.2317e-01,\n",
       "           -6.4963e-01,  7.4381e-01]]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以看出来网络输入输出都是一样的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=output\n",
    "base_height_f = x.shape[2]\n",
    "base_width_f = x.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scale=1\n",
    "max_scale=2**-3\n",
    "num_scales=5\n",
    "\n",
    "scale_log_factors = np.linspace(np.log(max_scale), np.log(min_scale), num_scales)\n",
    "scale_factors = np.exp(scale_log_factors)\n",
    "\n",
    "for i, s in enumerate(scale_factors):\n",
    "    \n",
    "    # scale are defined by extracted patch size (s of s*default_patch_size) so we need use inv-scale for resizing images\n",
    "#     inv_s=1.0/s\n",
    "    feat_height = (base_height_f * s + 0.5).astype(np.uint32)\n",
    "    feat_width = (base_width_f * s + 0.5).astype(np.uint32)\n",
    "    rs_feat_maps=torch.nn.functional.interpolate(x,[feat_height, feat_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 968, 1296])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_feat_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_s=1.0/scale_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7744"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125     , 0.2102241 , 0.35355339, 0.59460356, 1.        ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 4.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,3, 3)\n",
    "        nn.init.uniform_(self.conv1.weight,a=0,b=0)\n",
    "        nn.init.uniform_(self.conv1.bias,a=0,b=0)\n",
    "        nn.init.constant_(self.conv1.bias,val=4)\n",
    "#         K = torch.Tensor([[1 ,0, -1],[2, 0 ,-2], [1, 0 ,-1]])\n",
    "# #        I think I should make the shape/size like this?\n",
    "#         K = torch.unsqueeze(torch.unsqueeze(K,0),0)\n",
    "#         #with torch.no_grad():\n",
    "#         with torch.no_grad():\n",
    "#             self.conv1.weight = torch.nn.Parameter(K)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.conv1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_fill_ only supports a 0-dimensional value tensor, but got tensor with 1 dimension(s).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-23804cf32e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3-theano/lib/python3.6/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mconstant_\u001b[0;34m(tensor, val)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_fill_ only supports a 0-dimensional value tensor, but got tensor with 1 dimension(s)."
     ]
    }
   ],
   "source": [
    "w = torch.empty(1, 5)\n",
    "nn.init.constant_(w,val=torch.tensor([1,2,3,4,5]))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,0,3], dtype=torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([[1.0,2,3],[4.0,5,6],[7.0,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = l2normalize(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0592, 0.1185, 0.1777],\n",
       "        [0.2369, 0.2962, 0.3554],\n",
       "        [0.4146, 0.4739, 0.5331]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(input_data, requires_grad=True)\n",
    "norm = x.norm(p=2, dim=1, keepdim=True)\n",
    "x_normalized = x.div(norm.expand_as(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2673, 0.5345, 0.8018],\n",
       "        [0.4558, 0.5698, 0.6838],\n",
       "        [0.5026, 0.5744, 0.6462]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    def __init__(self,n_channels, scale):\n",
    "        super(L2Norm,self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.gamma = scale or None\n",
    "        self.eps = 1e-10\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.n_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.constant_(self.weight,self.gamma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()+self.eps\n",
    "        #x /= norm\n",
    "        x = torch.div(x,norm)\n",
    "        out = self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x) * x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=L2Norm(16,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.9875e+22, -2.2435e+23, -4.2435e+23,  ..., -4.8818e+23,\n",
       "           -3.2238e+23, -4.5585e+23],\n",
       "          [-4.5239e+23, -1.5145e+23, -5.9890e+22,  ..., -2.2507e+23,\n",
       "           -7.5980e+22, -2.5818e+23],\n",
       "          [-8.5684e+22, -2.5993e+23, -2.4635e+23,  ..., -4.4587e+23,\n",
       "           -1.9367e+23, -2.9402e+23],\n",
       "          ...,\n",
       "          [-3.8787e+23, -1.3569e+23, -8.5363e+21,  ..., -5.4141e+23,\n",
       "           -2.6103e+23, -3.7902e+23],\n",
       "          [-3.8192e+23, -1.2533e+23, -2.5346e+23,  ..., -2.2754e+23,\n",
       "           -6.0112e+22, -1.1252e+23],\n",
       "          [-4.2629e+23, -4.0428e+23, -3.3172e+23,  ..., -3.5366e+23,\n",
       "           -3.9935e+23, -3.7598e+23]],\n",
       "\n",
       "         [[ 6.3311e-42,  1.3472e-41,  6.5511e-42,  ...,  1.9802e-41,\n",
       "            7.0205e-43,  9.1295e-42],\n",
       "          [ 5.9906e-42,  1.1331e-41,  2.7157e-42,  ...,  1.5414e-44,\n",
       "            2.1193e-41,  1.4981e-41],\n",
       "          [ 1.9286e-41,  1.5190e-42,  1.5468e-41,  ...,  6.5581e-43,\n",
       "            1.2217e-41,  1.1835e-41],\n",
       "          ...,\n",
       "          [ 1.0455e-41,  1.9848e-41,  7.4997e-42,  ...,  1.6255e-42,\n",
       "            2.4663e-42,  9.4462e-42],\n",
       "          [ 1.3413e-41,  1.8407e-41,  1.9952e-41,  ...,  1.1861e-41,\n",
       "            7.7422e-42,  9.4938e-42],\n",
       "          [ 7.7604e-42,  1.1645e-41,  1.0187e-41,  ...,  1.6795e-41,\n",
       "            1.5882e-41,  1.2238e-41]],\n",
       "\n",
       "         [[-2.2803e+23, -3.8328e+23, -3.5215e+23,  ..., -2.4608e+22,\n",
       "           -2.1515e+23, -1.2011e+23],\n",
       "          [-1.3683e+23, -1.2002e+23, -4.0005e+23,  ..., -2.9201e+23,\n",
       "           -1.7912e+23, -3.7175e+23],\n",
       "          [-4.7564e+23, -2.8101e+23, -8.5440e+22,  ..., -4.3168e+23,\n",
       "           -1.4644e+23, -2.8563e+23],\n",
       "          ...,\n",
       "          [-1.9761e+23, -1.3407e+23, -3.7340e+23,  ..., -1.0050e+23,\n",
       "           -1.4646e+23, -1.7258e+23],\n",
       "          [-2.9746e+23, -1.3641e+23, -1.3647e+23,  ..., -2.5741e+23,\n",
       "           -7.6382e+22, -2.0627e+23],\n",
       "          [-1.2780e+23, -1.3547e+23, -1.6845e+22,  ..., -3.4257e+23,\n",
       "           -1.4182e+23, -2.6410e+23]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand([1, 16, 968, 1296])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.4584e-02, 4.4076e-01, 8.6257e-01,  ..., 9.2973e-01,\n",
       "           7.0214e-01, 9.3593e-01],\n",
       "          [9.4628e-01, 3.0881e-01, 1.0506e-01,  ..., 5.0020e-01,\n",
       "           1.3674e-01, 6.7434e-01],\n",
       "          [1.7106e-01, 5.6026e-01, 5.9777e-01,  ..., 9.2645e-01,\n",
       "           3.8451e-01, 7.7736e-01],\n",
       "          ...,\n",
       "          [7.0813e-01, 2.3430e-01, 1.6523e-02,  ..., 8.7827e-01,\n",
       "           4.4968e-01, 8.9249e-01],\n",
       "          [9.8822e-01, 2.7966e-01, 4.9337e-01,  ..., 5.1153e-01,\n",
       "           1.2078e-01, 2.6221e-01],\n",
       "          [9.3376e-01, 9.5439e-01, 7.9173e-01,  ..., 8.6261e-01,\n",
       "           9.0274e-01, 9.5543e-01]],\n",
       "\n",
       "         [[3.1928e-01, 6.2933e-01, 3.1664e-01,  ..., 8.9669e-01,\n",
       "           3.6332e-02, 4.4568e-01],\n",
       "          [2.9792e-01, 5.4931e-01, 1.1329e-01,  ..., 7.9715e-04,\n",
       "           9.0684e-01, 9.3040e-01],\n",
       "          [9.1546e-01, 7.7832e-02, 8.9237e-01,  ..., 3.2413e-02,\n",
       "           5.7670e-01, 7.4403e-01],\n",
       "          ...,\n",
       "          [4.5385e-01, 8.1488e-01, 3.4518e-01,  ..., 6.2675e-02,\n",
       "           1.0104e-01, 5.2888e-01],\n",
       "          [8.2525e-01, 9.7658e-01, 9.2341e-01,  ..., 6.3396e-01,\n",
       "           3.6984e-01, 5.2600e-01],\n",
       "          [4.0414e-01, 6.5363e-01, 5.7815e-01,  ..., 9.7401e-01,\n",
       "           8.5364e-01, 7.3940e-01]],\n",
       "\n",
       "         [[4.8370e-01, 7.5299e-01, 7.1581e-01,  ..., 4.6866e-02,\n",
       "           4.6861e-01, 2.4660e-01],\n",
       "          [2.8621e-01, 2.4473e-01, 7.0176e-01,  ..., 6.4897e-01,\n",
       "           3.2234e-01, 9.7099e-01],\n",
       "          [9.4955e-01, 6.0569e-01, 2.0732e-01,  ..., 8.9697e-01,\n",
       "           2.9073e-01, 7.5517e-01],\n",
       "          ...,\n",
       "          [3.6078e-01, 2.3151e-01, 7.2276e-01,  ..., 1.6304e-01,\n",
       "           2.5232e-01, 4.0639e-01],\n",
       "          [7.6968e-01, 3.0438e-01, 2.6564e-01,  ..., 5.7870e-01,\n",
       "           1.5347e-01, 4.8069e-01],\n",
       "          [2.7995e-01, 3.1981e-01, 4.0206e-02,  ..., 8.3556e-01,\n",
       "           3.2060e-01, 6.7113e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8.9021e-01, 2.8964e-02, 6.1309e-01,  ..., 2.6069e-01,\n",
       "           7.0782e-01, 8.7259e-01],\n",
       "          [8.9826e-01, 4.5034e-02, 4.8789e-01,  ..., 9.1454e-01,\n",
       "           2.7935e-01, 9.0966e-01],\n",
       "          [1.5739e-01, 3.5509e-01, 6.6412e-01,  ..., 3.5764e-01,\n",
       "           1.7923e-01, 5.7411e-01],\n",
       "          ...,\n",
       "          [1.9440e-01, 9.6162e-01, 1.8340e-01,  ..., 4.9724e-01,\n",
       "           2.7575e-01, 8.7733e-01],\n",
       "          [2.2869e-01, 9.6542e-01, 2.8556e-01,  ..., 6.0820e-01,\n",
       "           9.2954e-01, 3.6706e-01],\n",
       "          [2.1609e-01, 8.6578e-01, 6.7708e-01,  ..., 7.5611e-01,\n",
       "           3.2882e-01, 1.6388e-01]],\n",
       "\n",
       "         [[7.3596e-01, 3.4907e-01, 1.4047e-01,  ..., 1.3690e-01,\n",
       "           1.0786e-01, 8.4918e-02],\n",
       "          [9.5347e-02, 4.0754e-01, 1.9685e-01,  ..., 1.1242e-01,\n",
       "           7.2552e-01, 8.9026e-01],\n",
       "          [6.7934e-01, 9.6173e-01, 7.0155e-01,  ..., 6.7145e-01,\n",
       "           9.1000e-01, 3.6987e-01],\n",
       "          ...,\n",
       "          [2.8601e-01, 4.4291e-01, 8.0565e-01,  ..., 4.3761e-01,\n",
       "           1.6443e-01, 7.5045e-01],\n",
       "          [3.8319e-01, 4.5086e-01, 7.4002e-01,  ..., 9.7006e-01,\n",
       "           6.0631e-02, 8.7806e-01],\n",
       "          [7.3214e-02, 3.4759e-01, 8.1758e-01,  ..., 7.7813e-01,\n",
       "           2.0919e-01, 3.9458e-01]],\n",
       "\n",
       "         [[5.8836e-01, 6.1773e-01, 9.4433e-01,  ..., 3.1004e-01,\n",
       "           7.5438e-02, 8.7988e-01],\n",
       "          [2.2677e-01, 8.0666e-01, 6.3066e-01,  ..., 7.9433e-01,\n",
       "           4.9393e-01, 3.2341e-01],\n",
       "          [2.9167e-01, 3.3974e-01, 4.9349e-01,  ..., 4.6063e-01,\n",
       "           8.6926e-01, 4.4459e-01],\n",
       "          ...,\n",
       "          [3.0970e-01, 1.6909e-01, 3.5703e-01,  ..., 5.9047e-01,\n",
       "           1.2102e-01, 8.1338e-01],\n",
       "          [9.2963e-01, 1.1863e-01, 3.5516e-02,  ..., 5.3083e-01,\n",
       "           9.8313e-01, 9.1033e-01],\n",
       "          [4.7523e-01, 1.2037e-01, 1.8793e-02,  ..., 4.9918e-01,\n",
       "           5.4058e-01, 2.8780e-01]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(x, requires_grad=True)\n",
    "norm = x1.norm(p=2, dim=1, keepdim=True)\n",
    "x_normalized1 = x1.div(norm.expand_as(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.6655e-02, 2.0623e-01, 3.9009e-01,  ..., 4.4876e-01,\n",
       "           2.9635e-01, 4.1904e-01],\n",
       "          [4.1586e-01, 1.3922e-01, 5.5054e-02,  ..., 2.0689e-01,\n",
       "           6.9844e-02, 2.3733e-01],\n",
       "          [7.8766e-02, 2.3894e-01, 2.2646e-01,  ..., 4.0987e-01,\n",
       "           1.7804e-01, 2.7028e-01],\n",
       "          ...,\n",
       "          [3.5655e-01, 1.2473e-01, 7.8470e-03,  ..., 4.9769e-01,\n",
       "           2.3995e-01, 3.4842e-01],\n",
       "          [3.5108e-01, 1.1521e-01, 2.3299e-01,  ..., 2.0916e-01,\n",
       "           5.5258e-02, 1.0343e-01],\n",
       "          [3.9187e-01, 3.7164e-01, 3.0493e-01,  ..., 3.2510e-01,\n",
       "           3.6710e-01, 3.4562e-01]],\n",
       "\n",
       "         [[1.3836e-01, 2.9447e-01, 1.4320e-01,  ..., 4.3281e-01,\n",
       "           1.5335e-02, 1.9954e-01],\n",
       "          [1.3093e-01, 2.4764e-01, 5.9369e-02,  ..., 3.2972e-04,\n",
       "           4.6321e-01, 3.2745e-01],\n",
       "          [4.2154e-01, 3.3194e-02, 3.3806e-01,  ..., 1.4340e-02,\n",
       "           2.6702e-01, 2.5869e-01],\n",
       "          ...,\n",
       "          [2.2852e-01, 4.3382e-01, 1.6393e-01,  ..., 3.5516e-02,\n",
       "           5.3915e-02, 2.0647e-01],\n",
       "          [2.9318e-01, 4.0233e-01, 4.3608e-01,  ..., 2.5922e-01,\n",
       "           1.6921e-01, 2.0749e-01],\n",
       "          [1.6961e-01, 2.5452e-01, 2.2267e-01,  ..., 3.6708e-01,\n",
       "           3.4713e-01, 2.6747e-01]],\n",
       "\n",
       "         [[2.0962e-01, 3.5233e-01, 3.2372e-01,  ..., 2.2621e-02,\n",
       "           1.9778e-01, 1.1041e-01],\n",
       "          [1.2578e-01, 1.1033e-01, 3.6775e-01,  ..., 2.6843e-01,\n",
       "           1.6465e-01, 3.4173e-01],\n",
       "          [4.3723e-01, 2.5832e-01, 7.8541e-02,  ..., 3.9682e-01,\n",
       "           1.3461e-01, 2.6257e-01],\n",
       "          ...,\n",
       "          [1.8166e-01, 1.2325e-01, 3.4325e-01,  ..., 9.2389e-02,\n",
       "           1.3464e-01, 1.5865e-01],\n",
       "          [2.7344e-01, 1.2540e-01, 1.2545e-01,  ..., 2.3663e-01,\n",
       "           7.0214e-02, 1.8962e-01],\n",
       "          [1.1748e-01, 1.2453e-01, 1.5485e-02,  ..., 3.1490e-01,\n",
       "           1.3037e-01, 2.4278e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.8578e-01, 1.3552e-02, 2.7726e-01,  ..., 1.2583e-01,\n",
       "           2.9874e-01, 3.9068e-01],\n",
       "          [3.9476e-01, 2.0302e-02, 2.5567e-01,  ..., 3.7827e-01,\n",
       "           1.4269e-01, 3.2015e-01],\n",
       "          [7.2472e-02, 1.5144e-01, 2.5159e-01,  ..., 1.5822e-01,\n",
       "           8.2985e-02, 1.9961e-01],\n",
       "          ...,\n",
       "          [9.7883e-02, 5.1194e-01, 8.7102e-02,  ..., 2.8177e-01,\n",
       "           1.4714e-01, 3.4250e-01],\n",
       "          [8.1243e-02, 3.9773e-01, 1.3486e-01,  ..., 2.4869e-01,\n",
       "           4.2529e-01, 1.4479e-01],\n",
       "          [9.0688e-02, 3.3713e-01, 2.6077e-01,  ..., 2.8496e-01,\n",
       "           1.3372e-01, 5.9284e-02]],\n",
       "\n",
       "         [[3.1894e-01, 1.6333e-01, 6.3527e-02,  ..., 6.6080e-02,\n",
       "           4.5524e-02, 3.8020e-02],\n",
       "          [4.1903e-02, 1.8373e-01, 1.0316e-01,  ..., 4.6501e-02,\n",
       "           3.7059e-01, 3.1332e-01],\n",
       "          [3.1281e-01, 4.1017e-01, 2.6577e-01,  ..., 2.9705e-01,\n",
       "           4.2135e-01, 1.2860e-01],\n",
       "          ...,\n",
       "          [1.4401e-01, 2.3579e-01, 3.8262e-01,  ..., 2.4798e-01,\n",
       "           8.7743e-02, 2.9296e-01],\n",
       "          [1.3613e-01, 1.8575e-01, 3.4947e-01,  ..., 3.9665e-01,\n",
       "           2.7740e-02, 3.4637e-01],\n",
       "          [3.0726e-02, 1.3535e-01, 3.1489e-01,  ..., 2.9326e-01,\n",
       "           8.5068e-02, 1.4274e-01]],\n",
       "\n",
       "         [[2.5497e-01, 2.8904e-01, 4.2706e-01,  ..., 1.4965e-01,\n",
       "           3.1840e-02, 3.9394e-01],\n",
       "          [9.9658e-02, 3.6366e-01, 3.3049e-01,  ..., 3.2855e-01,\n",
       "           2.5230e-01, 1.1382e-01],\n",
       "          [1.3431e-01, 1.4490e-01, 1.8695e-01,  ..., 2.0379e-01,\n",
       "           4.0248e-01, 1.5458e-01],\n",
       "          ...,\n",
       "          [1.5594e-01, 9.0020e-02, 1.6956e-01,  ..., 3.3460e-01,\n",
       "           6.4576e-02, 3.1753e-01],\n",
       "          [3.3026e-01, 4.8874e-02, 1.6772e-02,  ..., 2.1706e-01,\n",
       "           4.4980e-01, 3.5910e-01],\n",
       "          [1.9944e-01, 4.6871e-02, 7.2380e-03,  ..., 1.8813e-01,\n",
       "           2.1983e-01, 1.0411e-01]]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_normalized1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
