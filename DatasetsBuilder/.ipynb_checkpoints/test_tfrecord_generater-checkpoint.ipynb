{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imageio import imread, imsave\n",
    "# import cv2\n",
    "import os\n",
    "root_dir='../dataset/scan'\n",
    "in_dir='../dataset/scan/color/'\n",
    "img_paths = [x.path for x in os.scandir(in_dir) if x.name.endswith('.jpg') or x.name.endswith('.png')]\n",
    "num_img=len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 1296, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imageio import imread, imsave\n",
    "photo = imread(img_paths[0])\n",
    "photo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些函数封装的真难用\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def write(input_file, output_file):\n",
    "    img_paths = [x.path for x in os.scandir(in_dir) if x.name.endswith('.jpg') or x.name.endswith('.png')]\n",
    "    num_img=len(img_paths)\n",
    "    file_names = [(root_dir+'/color/{}.jpg'.format(f)).encode() for f in range(num_img)]\n",
    "    writer = tf.python_io.TFRecordWriter(output_file) #定义writer，传入目标文件路径\n",
    "    \n",
    "    for i in range(num_img-15):\n",
    "        rgb1_filename = (root_dir+'/color/'+\"{}.jpg\".format(i)).encode()\n",
    "        rgb2_filename = (root_dir+'/color/'+\"{}.jpg\".format(i+10)).encode()\n",
    "        depth1_filename = (root_dir+'/depth/'+\"{}.jpg\".format(i)).encode()\n",
    "        depth2_filename = (root_dir+'/depth/'+\"{}.jpg\".format(i+10)).encode()\n",
    "        shape1 = (968, 1296, 3)\n",
    "        shape2 = (968, 1296, 3)\n",
    "#             bbox1\n",
    "#             bbox2\n",
    "        c1Tw = np.loadtxt(root_dir+'/pose/'+\"{}.txt\".format(i),dtype=np.float32).ravel()\n",
    "        c2Tw = np.loadtxt(root_dir+'/pose/'+\"{}.txt\".format(i+10),dtype=np.float32).ravel()\n",
    "        K1 = np.loadtxt(root_dir+'/intrinsic/'+\"intrinsic_color.txt\",dtype=np.float32).ravel()\n",
    "        K2 = np.loadtxt(root_dir+'/intrinsic/'+\"intrinsic_color.txt\",dtype=np.float32).ravel()\n",
    "        tf_example = tf.train.Example(\n",
    "            features=tf.train.Features(feature={\n",
    "                'rgb1_filename': bytes_feature(rgb1_filename),\n",
    "                'rgb2_filename': bytes_feature(rgb2_filename),\n",
    "                'depth1_filename': bytes_feature(depth1_filename),\n",
    "                'depth2_filename': bytes_feature(depth2_filename),\n",
    "                'shape1': tf.train.Feature(int64_list=tf.train.Int64List(value=list(shape1))),\n",
    "                'shape2': tf.train.Feature(int64_list=tf.train.Int64List(value=list(shape2))),\n",
    "    #             'bbox1': int64_feature(), # x1,x2,y1,y2\n",
    "    #             'bbox2': int64_feature(),\n",
    "                'c1Tw': tf.train.Feature(float_list=tf.train.FloatList(value=c1Tw)),\n",
    "                'c2Tw': tf.train.Feature(float_list=tf.train.FloatList(value=c2Tw)),\n",
    "                'K1': tf.train.Feature(float_list=tf.train.FloatList(value=K1)),\n",
    "                'K2': tf.train.Feature(float_list=tf.train.FloatList(value=K2)),\n",
    "        }))\n",
    "\n",
    "        #example序列化，并写入文件\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('.', 're.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_and_decode(file_name):\n",
    "    filename_queue = tf.train.string_input_producer([file_name])\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\"img_name\": tf.FixedLenFeature([], tf.string),\n",
    "                                                 \"raw_img\": tf.FixedLenFeature([], tf.string)})\n",
    "    img_name = features[\"img_name\"]\n",
    "    image = tf.decode_raw(features['raw_img'], tf.uint8)\n",
    "    image = tf.reshape(image, [256, 256, 3])\n",
    "    return img_name, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(['re.tfrecord'])\n",
    "reader = tf.TFRecordReader()\n",
    "\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "            features={\n",
    "                'rgb1_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'rgb2_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'depth1_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'depth2_filename': tf.FixedLenFeature([], tf.string),\n",
    "                'shape1': tf.FixedLenFeature([3], tf.int64),\n",
    "                'shape2': tf.FixedLenFeature([3], tf.int64),\n",
    "#                 'bbox1': tf.FixedLenFeature([4], tf.int64), # x1,x2,y1,y2\n",
    "#                 'bbox2': tf.FixedLenFeature([4], tf.int64),\n",
    "                'c1Tw': tf.FixedLenFeature([16], tf.float32),\n",
    "                'c2Tw': tf.FixedLenFeature([16], tf.float32),\n",
    "                'K1': tf.FixedLenFeature([16], tf.float32),\n",
    "                'K2': tf.FixedLenFeature([16], tf.float32),\n",
    "                                                                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.170188e+03 0.000000e+00 6.477500e+02 0.000000e+00 0.000000e+00\n",
      " 1.170188e+03 4.837500e+02 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 1.000000e+00]\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess: #开始一个会话\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    coord=tf.train.Coordinator()\n",
    "    threads= tf.train.start_queue_runners(coord=coord)\n",
    "    x= sess.run(features['K1'])#在会话中取出image和label\n",
    "    print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
